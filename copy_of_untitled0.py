# -*- coding: utf-8 -*-
"""Copy of Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rTri3yKrg1gGsxb9W4xhPIE4YT6S1Cxn
"""

pip install quandl

# program to predict stock prices using machine learning models
#dependency installation

import quandl
import numpy as np



from sklearn.linear_model import LinearRegression

#support vector machine
from sklearn.svm import SVR

# used to split and train our method
from sklearn.model_selection import train_test_split

#retreiving stock data
dataframe = quandl.get("WIKI/GOOGL")
#result of data from facebook
print(dataframe.head())

#we will use the adjacted closed column

#working with only the adjusted closed price
dataframe = dataframe[["Adj. Close"]]#adj.close is our independent variable
print(dataframe.head())

#predicting into the future variable for a number of days e.g 1
forecast_out = 30

#we need a target column which is shifted n units up

dataframe['Prediction'] = dataframe[['Adj. Close']].shift(-forecast_out) 
#use - to shift by the number of days
print(dataframe.head())


# As shown in the table, the prediction for different days shows a 
#different prediction on the next day we have shifted it to

#end of the data looks like
print(dataframe.head())

#it put NaN when it doesnt know what the data is
#we can see that dates are truly changed aswell.

#we are going to create the data set (x) which is independent.
#we do so by converting the dataframe into a numpy array

X = np.array(dataframe.drop(['Prediction'],1))
print(X)
#we drop the prediction column becuase we need the independent variable which
#which is the adj .close

#we now remove the last n rows
X = X[:-forecast_out]
print(X)

### creating the dependent data set (y)
##  We do this by converting the dataframe to a numpy array(this will include all the values NaN)
y = np.array(dataframe['Prediction'])
# We not need to get all the y values apart from last n rows

y = y[:-forecast_out]
print(y)
#what is happening here in the results below is that
## X is a list of List whilst y is simply a list

### now we will split the data into 80% training and 20% testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

#create/ training the support vector machine regressor
#we will use the svr function rbs is a curnul which stands for
##'radio bases curnul'
svr_rbf =SVR(kernel='rbf', C=1e3, gamma=0.1)
svr_rbf.fit(X_train, y_train)

#We will now test how good our model is using score
#it returns the coefficient of determination R^2 of prediction
#the best possible score is 1.0
#svm support vector machine
svm__confidence =  svr_rbf.score(X_test, y_test)
print("svm__confidence", svm__confidence)

#we are going to create a linear regression model
#we do so by lr
lr = LinearRegression()
#we train it by
lr.fit(X_train, y_train)

lr__confidence =  lr.score(X_test, y_test)
print("lr__confidence", lr__confidence)

#we are going to create the value with want to forecast on
x_forecast = np.array(dataframe.drop(['Prediction'],1))[-forecast_out:]
print(x_forecast)

#Printing linear regression model predictions for a certain n days
lr_prediction = lr.predict(x_forecast)
print(lr_prediction)

#Print support vector regressor model predictions for the next 'n' days
svm_prediction = svr_rbf.predict(x_forecast)
print(svm_prediction)